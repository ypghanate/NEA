{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ypghanate/NEA/blob/main/NEA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2WAoS2qdNsf",
        "outputId": "d26a9885-34e8-4f33-d800-8cf788a93194"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: cpu\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Epoch 1: loss = 0.6111\n",
            "Epoch 2: loss = 0.1472\n",
            "Epoch 3: loss = 0.0674\n",
            "Epoch 4: loss = 0.0633\n",
            "Epoch 5: loss = 0.0619\n",
            "Epoch 6: loss = 0.0602\n",
            "Epoch 7: loss = 0.0612\n",
            "Epoch 8: loss = 0.0596\n",
            "Epoch 9: loss = 0.0597\n",
            "Epoch 10: loss = 0.0595\n",
            "Epoch 11: loss = 0.0595\n",
            "Epoch 12: loss = 0.0593\n",
            "Epoch 13: loss = 0.0588\n",
            "Epoch 14: loss = 0.0588\n",
            "Epoch 15: loss = 0.0599\n",
            "Epoch 16: loss = 0.0593\n",
            "Epoch 17: loss = 0.0591\n",
            "Epoch 18: loss = 0.0596\n",
            "Epoch 19: loss = 0.0591\n",
            "Epoch 20: loss = 0.0589\n",
            "Saved model.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files, drive\n",
        "import pretty_midi\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from music21 import converter\n",
        "from scipy import ndimage\n",
        "\n",
        "!pip install pretty_midi music21 torch scipy --quiet\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using:\", device)\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def midi_to_pianoroll(midi_file, fs=16):\n",
        "    midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
        "    n_steps = int(midi_data.get_end_time() * fs) + 1\n",
        "    roll = np.zeros((n_steps, 88), dtype=np.float32)\n",
        "    for inst in midi_data.instruments:\n",
        "        for n in inst.notes:\n",
        "            idx = n.pitch - 21\n",
        "            if 0 <= idx < 88:\n",
        "                roll[int(n.start*fs):int(n.end*fs), idx] = n.velocity / 127.0\n",
        "    return roll\n",
        "\n",
        "def smooth_roll_temporal(roll, window=3):\n",
        "    smoothed = np.zeros_like(roll)\n",
        "    for pitch_idx in range(roll.shape[1]):\n",
        "        smoothed[:, pitch_idx] = ndimage.uniform_filter1d(\n",
        "            roll[:, pitch_idx], size=window, mode='constant')\n",
        "    return smoothed\n",
        "\n",
        "def threshold_and_clean_roll(roll, threshold=0.5, min_duration_steps=3):\n",
        "    binary = (roll > threshold).astype(np.float32)\n",
        "    n_steps, n_notes = binary.shape\n",
        "    cleaned = np.zeros_like(binary)\n",
        "    for pitch_idx in range(n_notes):\n",
        "        i = 0\n",
        "        while i < n_steps:\n",
        "            if binary[i, pitch_idx]:\n",
        "                j = i\n",
        "                while j < n_steps and binary[j, pitch_idx]:\n",
        "                    j += 1\n",
        "                if j - i >= min_duration_steps:\n",
        "                    cleaned[i:j, pitch_idx] = roll[i:j, pitch_idx]\n",
        "                i = j\n",
        "            else:\n",
        "                i += 1\n",
        "    return cleaned\n",
        "\n",
        "def reduce_simultaneous_notes(roll, max_simultaneous=6):\n",
        "    out = np.zeros_like(roll)\n",
        "    for t in range(roll.shape[0]):\n",
        "        active = np.where(roll[t] > 0)[0]\n",
        "        if len(active) <= max_simultaneous:\n",
        "            out[t, active] = roll[t, active]\n",
        "        else:\n",
        "            chosen = active[np.argsort(roll[t, active])[-max_simultaneous:]]\n",
        "            out[t, chosen] = roll[t, chosen]\n",
        "    return out\n",
        "\n",
        "def pianoroll_to_midi(roll, output_file, fs=16):\n",
        "    midi = pretty_midi.PrettyMIDI(initial_tempo=120)\n",
        "    piano = pretty_midi.Instrument(program=0)\n",
        "\n",
        "    n_steps, n_notes = roll.shape\n",
        "    active = {}\n",
        "\n",
        "    for t in range(n_steps):\n",
        "        for p in range(n_notes):\n",
        "            v = roll[t, p]\n",
        "            pitch = p + 21\n",
        "            if v > 0.1:\n",
        "                if p not in active:\n",
        "                    active[p] = (t/fs, int(v*127))\n",
        "            else:\n",
        "                if p in active:\n",
        "                    start, vel = active[p]\n",
        "                    end = t/fs\n",
        "                    if end > start + 0.03:\n",
        "                        piano.notes.append(pretty_midi.Note(\n",
        "                            velocity=vel, pitch=pitch, start=start, end=end))\n",
        "                    del active[p]\n",
        "\n",
        "    midi.instruments.append(piano)\n",
        "    midi.write(output_file)\n",
        "    return len(piano.notes)\n",
        "\n",
        "def note_density(roll):\n",
        "    return float(np.mean(np.sum(roll > 0, axis=1)))\n",
        "\n",
        "def key_complexity(midi_file):\n",
        "    try:\n",
        "        k = converter.parse(midi_file).analyze(\"key\")\n",
        "        return 0 if k.mode == \"major\" else 1\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "def pitch_complexity(roll):\n",
        "    active = np.where(roll > 0)[1]\n",
        "    if active.size == 0:\n",
        "        return 0\n",
        "    return 1 if np.ptp(active) > 12 else 0\n",
        "\n",
        "def overallComplexity(midi_file, roll):\n",
        "    score = note_density(roll) + key_complexity(midi_file) + pitch_complexity(roll)\n",
        "    return \"hard\" if score >= 3 else \"easy\"\n",
        "\n",
        "def pad(roll, length=600):\n",
        "    if roll.shape[0] > length:\n",
        "        return roll[:length]\n",
        "    return np.pad(roll, ((0, length-roll.shape[0]), (0,0)))\n",
        "\n",
        "def add_difficulty_channel(roll, target_diff):\n",
        "    extra = np.ones((roll.shape[0], 1), dtype=np.float32) if target_diff == \"hard\" else \\\n",
        "            np.zeros((roll.shape[0], 1), dtype=np.float32)\n",
        "    return np.concatenate([roll, extra], axis=1)\n",
        "\n",
        "class PianoRollDataset(Dataset):\n",
        "    def __init__(self, inp, tgt, diffs):\n",
        "        self.inputs = inp\n",
        "        self.targets = tgt\n",
        "        self.diffs = diffs\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "    def __getitem__(self, i):\n",
        "        return (torch.tensor(self.inputs[i]).float(),\n",
        "                torch.tensor(self.targets[i]).float())\n",
        "\n",
        "class SeqSimplifier(nn.Module):\n",
        "    def __init__(self, input_size=89, hidden=256, layers=2):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden, layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden, 88)\n",
        "        self.sig = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        y, _ = self.lstm(x)\n",
        "        return self.sig(self.fc(y))\n",
        "def midi_prep(folder):\n",
        "    inputs, targets, diffs = [], [], []\n",
        "    easy = os.path.join(folder, \"easy\")\n",
        "    med  = os.path.join(folder, \"medium\")\n",
        "    hard = os.path.join(folder, \"hard\")\n",
        "\n",
        "    for f in os.listdir(med):\n",
        "        if not f.endswith(\".mid\"):\n",
        "            continue\n",
        "        normal = os.path.join(med, f)\n",
        "        roll_norm = pad(midi_to_pianoroll(normal))\n",
        "\n",
        "        easy_path = os.path.join(easy, f.replace(\"medium\", \"easy\"))\n",
        "        hard_path = os.path.join(hard, f.replace(\"medium\", \"hard\"))\n",
        "\n",
        "        if os.path.exists(easy_path):\n",
        "            roll_easy = pad(midi_to_pianoroll(easy_path))\n",
        "            inputs.append(add_difficulty_channel(roll_norm, \"easy\"))\n",
        "            targets.append(roll_easy)\n",
        "            diffs.append(\"easy\")\n",
        "\n",
        "        if os.path.exists(hard_path):\n",
        "            roll_hard = pad(midi_to_pianoroll(hard_path))\n",
        "            inputs.append(add_difficulty_channel(roll_norm, \"hard\"))\n",
        "            targets.append(roll_hard)\n",
        "            diffs.append(\"hard\")\n",
        "\n",
        "    return PianoRollDataset(inputs, targets, diffs)\n",
        "\n",
        "midi_folder = \"/content/drive/MyDrive/dataset\"\n",
        "dataset = midi_prep(midi_folder)\n",
        "loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "model = SeqSimplifier().to(device)\n",
        "\n",
        "crit = nn.BCELoss()\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "EPOCHS = 20\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total = 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        out = model(x)\n",
        "        loss = crit(out, y)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        total += loss.item()\n",
        "    print(f\"Epoch {epoch+1}: loss = {total/len(loader):.4f}\")\n",
        "\n",
        "MODEL_PATH = \"/content/simplifier_model.pth\"\n",
        "torch.save(model.state_dict(), MODEL_PATH)\n",
        "print(\"Saved model.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files, drive\n",
        "import pretty_midi\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from music21 import converter\n",
        "from scipy import ndimage\n",
        "\n",
        "!pip install pretty_midi music21 torch scipy --quiet\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "uploaded = files.upload()\n",
        "midi_path = list(uploaded.keys())[0]\n",
        "\n",
        "def midi_to_pianoroll(midi_file, fs=16):\n",
        "    midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
        "    n_steps = int(midi_data.get_end_time() * fs) + 1\n",
        "    roll = np.zeros((n_steps, 88), dtype=np.float32)\n",
        "    for inst in midi_data.instruments:\n",
        "        for n in inst.notes:\n",
        "            idx = n.pitch - 21\n",
        "            if 0 <= idx < 88:\n",
        "                roll[int(n.start*fs):int(n.end*fs), idx] = n.velocity / 127.0\n",
        "    return roll\n",
        "\n",
        "def smooth_roll_temporal(roll, window=3):\n",
        "    smoothed = np.zeros_like(roll)\n",
        "    for pitch_idx in range(roll.shape[1]):\n",
        "        smoothed[:, pitch_idx] = ndimage.uniform_filter1d(roll[:, pitch_idx], size=window, mode='constant')\n",
        "    return smoothed\n",
        "\n",
        "def threshold_and_clean_roll(roll, threshold=0.5, min_duration_steps=3):\n",
        "    binary_roll = (roll > threshold).astype(np.float32)\n",
        "    n_steps, n_notes = binary_roll.shape\n",
        "    cleaned_roll = np.zeros_like(binary_roll)\n",
        "    for pitch_idx in range(n_notes):\n",
        "        i = 0\n",
        "        while i < n_steps:\n",
        "            if binary_roll[i, pitch_idx] > 0:\n",
        "                j = i\n",
        "                while j < n_steps and binary_roll[j, pitch_idx] > 0:\n",
        "                    j += 1\n",
        "                duration = j - i\n",
        "                if duration >= min_duration_steps:\n",
        "                    cleaned_roll[i:j, pitch_idx] = roll[i:j, pitch_idx]\n",
        "                i = j\n",
        "            else:\n",
        "                i += 1\n",
        "    return cleaned_roll\n",
        "\n",
        "def reduce_simultaneous_notes(roll, max_simultaneous=6):\n",
        "    n_steps, n_notes = roll.shape\n",
        "    reduced = np.zeros_like(roll)\n",
        "    for t in range(n_steps):\n",
        "        active = np.where(roll[t, :] > 0)[0]\n",
        "        if len(active) <= max_simultaneous:\n",
        "            reduced[t, active] = roll[t, active]\n",
        "        else:\n",
        "            top_indices = active[np.argsort(roll[t, active])[-max_simultaneous:]]\n",
        "            reduced[t, top_indices] = roll[t, top_indices]\n",
        "    return reduced\n",
        "\n",
        "def pianoroll_to_midi(roll, output_file, fs=16, velocity_threshold=0.1):\n",
        "    midi_data = pretty_midi.PrettyMIDI(initial_tempo=120)\n",
        "    midi_data.time_signature_changes.append(pretty_midi.TimeSignature(numerator=4, denominator=4, time=0))\n",
        "    piano = pretty_midi.Instrument(program=0, is_drum=False, name='Piano')\n",
        "    n_steps, n_notes = roll.shape\n",
        "    active_notes = {}\n",
        "    for t in range(n_steps):\n",
        "        for pitch_idx in range(n_notes):\n",
        "            vel = roll[t, pitch_idx]\n",
        "            pitch = pitch_idx + 21\n",
        "            if vel > velocity_threshold:\n",
        "                if pitch_idx not in active_notes:\n",
        "                    active_notes[pitch_idx] = (t/fs, max(30, int(vel * 127)))\n",
        "            else:\n",
        "                if pitch_idx in active_notes:\n",
        "                    start_time, velocity = active_notes[pitch_idx]\n",
        "                    end_time = t/fs\n",
        "                    if end_time > start_time + 0.05:\n",
        "                        piano.notes.append(pretty_midi.Note(velocity=velocity, pitch=pitch, start=start_time, end=end_time))\n",
        "                    del active_notes[pitch_idx]\n",
        "    final_time = n_steps / fs\n",
        "    for pitch_idx, (start_time, velocity) in active_notes.items():\n",
        "        if final_time > start_time + 0.05:\n",
        "            piano.notes.append(pretty_midi.Note(velocity=velocity, pitch=pitch_idx + 21, start=start_time, end=final_time))\n",
        "    if len(piano.notes) == 0:\n",
        "        piano.notes.append(pretty_midi.Note(velocity=64, pitch=60, start=0.0, end=1.0))\n",
        "    piano.notes.sort(key=lambda x: x.start)\n",
        "    midi_data.instruments.append(piano)\n",
        "    midi_data.write(output_file)\n",
        "    return len(piano.notes)\n",
        "\n",
        "def note_density(roll):\n",
        "    return float(np.mean(np.sum(roll > 0, axis=1)))\n",
        "\n",
        "def key_complexity(midi_file):\n",
        "    try:\n",
        "        k = converter.parse(midi_file).analyze('key')\n",
        "        if k.mode == 'major':\n",
        "            return 0\n",
        "        else:\n",
        "            return 1\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "def pitch_complexity(roll):\n",
        "    active_positions = np.where(roll > 0)\n",
        "    if active_positions[1].size == 0:\n",
        "        return 0\n",
        "    span = int(np.ptp(active_positions[1]))\n",
        "    if span > 12:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def overallComplexity(midi_file, roll):\n",
        "    score = note_density(roll) + key_complexity(midi_file) + pitch_complexity(roll)\n",
        "    if score >= 3:\n",
        "        return \"hard\"\n",
        "    else:\n",
        "        return \"easy\"\n",
        "\n",
        "def pad(roll, length=600):\n",
        "    if roll.shape[0] > length:\n",
        "        return roll[:length]\n",
        "    elif roll.shape[0] < length:\n",
        "        pad_amount = length - roll.shape[0]\n",
        "        return np.pad(roll, ((0, pad_amount), (0, 0)))\n",
        "    else:\n",
        "        return roll\n",
        "\n",
        "def add_difficulty_channel(roll, target_diff):\n",
        "    c = np.zeros((roll.shape[0], 1), np.float32)\n",
        "    if target_diff == 'hard':\n",
        "        c[:] = 1.0\n",
        "    return np.concatenate([roll, c], axis=1)\n",
        "\n",
        "class PianoRollDataset(Dataset):\n",
        "    def __init__(self, input_rolls, target_rolls, target_diffs):\n",
        "        self.inputs = input_rolls\n",
        "        self.targets = target_rolls\n",
        "        self.target_diffs = target_diffs\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "    def __getitem__(self, i):\n",
        "        return (torch.tensor(self.inputs[i]), torch.tensor(self.targets[i]), self.target_diffs[i])\n",
        "\n",
        "class SeqSimplifier(nn.Module):\n",
        "    def __init__(self, input_size=89, hidden=256, layers=2):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden, layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden, 88)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        y, _ = self.lstm(x)\n",
        "        return self.sigmoid(self.fc(y))\n",
        "\n",
        "def midi_prep(midi_folder):\n",
        "    inputs, targets, target_diffs = [], [], []\n",
        "\n",
        "    easy_folder = os.path.join(midi_folder, \"easy\")\n",
        "    normal_folder = os.path.join(midi_folder, \"medium\")\n",
        "    hard_folder = os.path.join(midi_folder, \"hard\")\n",
        "    max_length = 600\n",
        "\n",
        "    for file in os.listdir(normal_folder):\n",
        "        if not file.endswith(\".mid\"):\n",
        "            continue\n",
        "\n",
        "        normal_path = os.path.join(normal_folder, file)\n",
        "\n",
        "        easy_path = os.path.join(easy_folder, file.replace(\"medium\", \"easy\"))\n",
        "        hard_path = os.path.join(hard_folder, file.replace(\"medium\", \"hard\"))\n",
        "        normal_roll = pad(midi_to_pianoroll(normal_path), max_length)\n",
        "\n",
        "        if os.path.exists(easy_path):\n",
        "            easy_roll = pad(midi_to_pianoroll(easy_path), max_length)\n",
        "            inputs.append(add_difficulty_channel(normal_roll, 'easy'))\n",
        "            targets.append(easy_roll)\n",
        "            target_diffs.append(\"easy\")\n",
        "        if os.path.exists(hard_path):\n",
        "            hard_roll = pad(midi_to_pianoroll(hard_path), max_length)\n",
        "            inputs.append(add_difficulty_channel(normal_roll, 'hard'))\n",
        "            targets.append(hard_roll)\n",
        "            target_diffs.append(\"hard\")\n",
        "    return PianoRollDataset(inputs, targets, target_diffs)\n",
        "\n",
        "midi_folder = \"/content/drive/MyDrive/dataset\"\n",
        "dataset = midi_prep(midi_folder)\n",
        "loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "model = SeqSimplifier()\n",
        "MODEL_PATH = \"/content/simplifier_model.pth\"\n",
        "if os.path.exists(MODEL_PATH):\n",
        "    model.load_state_dict(torch.load(MODEL_PATH, map_location=\"cpu\"))\n",
        "model.eval()\n",
        "\n",
        "roll = midi_to_pianoroll(midi_path)\n",
        "user_skill = input(\"Enter your skill level: \").strip().lower()\n",
        "\n",
        "sheet_diff = overallComplexity(midi_path, roll)\n",
        "\n",
        "if sheet_diff == 'hard' and user_skill in ['easy', 'medium']:\n",
        "    target = 'easy'\n",
        "elif sheet_diff == 'easy' and user_skill == 'hard':\n",
        "    target = 'hard'\n",
        "else:\n",
        "    target = sheet_diff\n",
        "\n",
        "roll_input = add_difficulty_channel(roll, target)\n",
        "roll_tensor = torch.tensor(roll_input[None, :, :]).float()\n",
        "\n",
        "with torch.no_grad():\n",
        "    simplified = model(roll_tensor).squeeze(0).numpy()\n",
        "\n",
        "simplified = smooth_roll_temporal(simplified, window=3)\n",
        "simplified = threshold_and_clean_roll(simplified, threshold=0.5, min_duration_steps=5)\n",
        "simplified = reduce_simultaneous_notes(simplified, max_simultaneous=4)\n",
        "\n",
        "num_notes = pianoroll_to_midi(simplified, \"generated_song.mid\", fs=16)\n",
        "if num_notes < 10:\n",
        "    pianoroll_to_midi(roll * 0.5, \"generated_song.mid\", fs=16)\n",
        "\n",
        "score = converter.parse(\"generated_song.mid\")\n",
        "xml_file = \"generated_song.xml\"\n",
        "score.write('musicxml', fp=xml_file)\n",
        "files.download(xml_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "rD4cUQBycPen",
        "outputId": "6045f1c8-dd90-490a-a34f-93096b8525d6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-85857aec-7e4a-4b91-beef-b33cf883136c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-85857aec-7e4a-4b91-beef-b33cf883136c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving abcdeg.mid to abcdeg (1).mid\n",
            "Enter your skill level: hard\n",
            "this is target hard\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_24fc28af-5152-4b87-b76a-176f959aca10\", \"generated_song.xml\", 3841)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def smooth_roll_temporal(roll, window=3):\n",
        "#     smoothed = np.zeros_like(roll)\n",
        "#     for pitch_idx in range(roll.shape[1]):\n",
        "#         smoothed[:, pitch_idx] = ndimage.uniform_filter1d(roll[:, pitch_idx], size=window, mode='constant')\n",
        "#     return smoothed\n",
        "\n",
        "# def threshold_and_clean_roll(roll, threshold=0.5, min_duration_steps=3):\n",
        "#     binary_roll = (roll > threshold).astype(np.float32)\n",
        "#     n_steps, n_notes = binary_roll.shape\n",
        "#     cleaned_roll = np.zeros_like(binary_roll)\n",
        "#     for pitch_idx in range(n_notes):\n",
        "#         i = 0\n",
        "#         while i < n_steps:\n",
        "#             if binary_roll[i, pitch_idx] > 0:\n",
        "#                 j = i\n",
        "#                 while j < n_steps and binary_roll[j, pitch_idx] > 0:\n",
        "#                     j += 1\n",
        "#                 duration = j - i\n",
        "#                 if duration >= min_duration_steps:\n",
        "#                     cleaned_roll[i:j, pitch_idx] = roll[i:j, pitch_idx]\n",
        "#                 i = j\n",
        "#             else:\n",
        "#                 i += 1\n",
        "#     return cleaned_roll\n",
        "\n",
        "# def reduce_simultaneous_notes(roll, max_simultaneous=6):\n",
        "#     n_steps, n_notes = roll.shape\n",
        "#     reduced = np.zeros_like(roll)\n",
        "#     for t in range(n_steps):\n",
        "#         active = np.where(roll[t, :] > 0)[0]\n",
        "#         if len(active) <= max_simultaneous:\n",
        "#             reduced[t, active] = roll[t, active]\n",
        "#         else:\n",
        "#             top_indices = active[np.argsort(roll[t, active])[-max_simultaneous:]]\n",
        "#             reduced[t, top_indices] = roll[t, top_indices]\n",
        "#     return reduced\n",
        "\n",
        "# def adaptive_threshold(roll, min_notes=20, max_notes=80):\n",
        "#     best_thresh = None\n",
        "#     best_score = float(\"inf\")\n",
        "#     best_cleaned = None\n",
        "#     center = (min_notes + max_notes) / 2.0\n",
        "#     for thresh in [0.6, 0.5, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1]:\n",
        "#         cleaned = threshold_and_clean_roll(roll, threshold=thresh, min_duration_steps=4)\n",
        "#         cleaned = reduce_simultaneous_notes(cleaned, max_simultaneous=6)\n",
        "#         note_count = int(np.sum(np.any(cleaned > 0, axis=0)))\n",
        "#         avg_polyphony = float(np.mean(np.sum(cleaned > 0, axis=1)))\n",
        "#         score = abs(note_count - center) + max(0.0, avg_polyphony - 8.0) * 10.0\n",
        "#         if score < best_score:\n",
        "#             best_score = score\n",
        "#             best_thresh = thresh\n",
        "#             best_cleaned = cleaned\n",
        "#     return best_cleaned, best_thresh"
      ],
      "metadata": {
        "id": "xyNidow6itrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "5fd534b8",
        "outputId": "39d3e43b-2d2e-40b8-a291-5eb87800cef3"
      },
      "source": [
        "!pip install pretty_midi music21 torch --quiet\n",
        "\n",
        "import os, numpy as np, torch, torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pretty_midi\n",
        "from music21 import converter\n",
        "\n",
        "def midi_to_pianoroll(midi_file, fs=16):\n",
        "    midi_data = pretty_midi.PrettyMIDI(midi_file)\n",
        "    n_steps = int(midi_data.get_end_time() * fs) + 1\n",
        "    roll = np.zeros((n_steps, 88), dtype=np.float32)\n",
        "    for inst in midi_data.instruments:\n",
        "        for n in inst.notes:\n",
        "            idx = n.pitch - 21\n",
        "            if 0 <= idx < 88:\n",
        "                roll[int(n.start*fs):int(n.end*fs), idx] = n.velocity / 127.0\n",
        "    return roll\n",
        "\n",
        "\n",
        "def note_density(roll):\n",
        "    return np.mean(np.sum(roll > 0, axis=1))\n",
        "\n",
        "def key_complexity(midi_file):\n",
        "    k = converter.parse(midi_file).analyze('key')\n",
        "    return 0 if k.mode == 'major' else 1\n",
        "\n",
        "def pitch_complexity(roll):\n",
        "    return int(np.ptp(np.where(roll > 0)[1]) > 12)\n",
        "\n",
        "def overallComplexity(midi_file, roll):\n",
        "    score = note_density(roll) + key_complexity(midi_file) + pitch_complexity(roll)\n",
        "    return \"hard\" if score >= 3 else \"easy\"\n",
        "\n",
        "def add_difficulty_channel(roll, target_diff):\n",
        "    c = np.ones((roll.shape[0], 1), np.float32)\n",
        "    if target_diff == 'easy':\n",
        "        c[:] = 0\n",
        "    elif target_diff == 'hard':\n",
        "        c[:] = 1\n",
        "    return np.concatenate([roll, c], axis=1)\n",
        "\n",
        "def pad(roll, length=600):\n",
        "  if roll.shape[0] > length:\n",
        "    return roll[:length]\n",
        "  elif roll.shape[0] < length:\n",
        "    pad_amount = length - roll.shape[0]\n",
        "    return np.pad(roll, ((0, pad_amount), (0, 0)))\n",
        "  else:\n",
        "    return roll\n",
        "\n",
        "class PianoRollDataset(Dataset):\n",
        "    def __init__(self, input_rolls, target_rolls, target_diffs):\n",
        "        self.inputs = input_rolls\n",
        "        self.targets = target_rolls\n",
        "        self.target_diffs = target_diffs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (torch.tensor(self.inputs[i]), torch.tensor(self.targets[i]), self.target_diffs[i])\n",
        "\n",
        "def midi_prep(midi_folder):\n",
        "    inputs, targets, target_diffs = [], [], []\n",
        "\n",
        "    easy_folder = os.path.join(midi_folder, \"easy\")\n",
        "    normal_folder = os.path.join(midi_folder, \"medium\")\n",
        "    hard_folder = os.path.join(midi_folder, \"hard\")\n",
        "\n",
        "    max_length = 600\n",
        "\n",
        "    for file in os.listdir(normal_folder):\n",
        "      if not file.endswith(\".mid\"):\n",
        "        continue\n",
        "\n",
        "      normal_file = file\n",
        "      easy_file = normal_file.replace(\"medium\", \"easy\")\n",
        "      hard_file = normal_file.replace(\"medium\", \"hard\")\n",
        "\n",
        "\n",
        "      normal_path = os.path.join(normal_folder, normal_file)\n",
        "      easy_path = os.path.join(easy_folder, easy_file)\n",
        "      hard_path = os.path.join(hard_folder, hard_file)\n",
        "\n",
        "      normal_roll = midi_to_pianoroll(normal_path)\n",
        "      normal_roll = pad(normal_roll, max_length)\n",
        "\n",
        "      if os.path.exists(easy_path):\n",
        "          easy_roll = midi_to_pianoroll(easy_path)\n",
        "          easy_roll = pad(easy_roll, max_length)\n",
        "          inputs.append(add_difficulty_channel(normal_roll, 'easy'))\n",
        "          targets.append(easy_roll)\n",
        "          target_diffs.append(\"easy\")\n",
        "\n",
        "      if os.path.exists(hard_path):\n",
        "          hard_roll = midi_to_pianoroll(hard_path)\n",
        "          hard_roll = pad(hard_roll, max_length)\n",
        "          inputs.append(add_difficulty_channel(normal_roll, 'hard'))\n",
        "          targets.append(hard_roll)\n",
        "          target_diffs.append(\"hard\")\n",
        "\n",
        "      normal_roll = pad(midi_to_pianoroll(normal_path), max_length)\n",
        "      easy_roll = pad(midi_to_pianoroll(easy_path), max_length)\n",
        "      hard_roll = pad(midi_to_pianoroll(hard_path), max_length)\n",
        "\n",
        "    return PianoRollDataset(inputs, targets, target_diffs)\n",
        "\n",
        "class SeqSimplifier(nn.Module):\n",
        "    def __init__(self, input_size=89, hidden=256, layers=2):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden, layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden, 88)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        y, _ = self.lstm(x)\n",
        "        return self.sigmoid(self.fc(y))\n",
        "\n",
        "\n",
        "midi_folder = \"/content/drive/MyDrive/dataset/\"\n",
        "dataset = midi_prep(midi_folder)\n",
        "loader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "model = SeqSimplifier()\n",
        "crit = nn.BCELoss()\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "print(f\"Training on {len(dataset)} pairs...\")\n",
        "\n",
        "for epoch in range(20):\n",
        "    total_loss = 0\n",
        "    for x, y, target_diffs in loader:\n",
        "        opt.zero_grad()\n",
        "        out = model(x)\n",
        "        loss = crit(out, y)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1:02d} | loss = {total_loss / len(loader):.4f}\")\n",
        "\n",
        "print(\"Training complete.\")\n",
        "torch.save(model.state_dict(), \"simplifier_model.pth\")\n",
        "print(\"Model saved as simplifier_model.pth\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on 30 pairs...\n",
            "Epoch 01 | loss = 0.6092\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2060414963.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             )\n\u001b[0;32m--> 625\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/HemantKArya/Melodfy.git\n",
        "%cd Melodfy\n",
        "\n",
        "!pip install --upgrade pip setuptools wheel\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "!pip install .\n",
        "\n",
        "!ffmpeg -version\n",
        "\n",
        "from melodfy import audio_to_midi\n",
        "\n",
        "audio_file = \"my_piano.wav\"\n",
        "output_midi = \"output.mid\"\n",
        "\n",
        "audio_to_midi(audio_file, output_midi)\n",
        "print(\"Conversion complete! Saved as:\", output_midi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oIVYztFys0g_",
        "outputId": "141ee28b-1c87-422b-c807-89305ffd0353",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Melodfy' already exists and is not an empty directory.\n",
            "/content/Melodfy\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (25.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (80.9.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.12/dist-packages (0.45.1)\n",
            "Collecting audioread@ git+https://github.com/HemantKArya/audioread.git (from -r requirements.txt (line 1))\n",
            "  Cloning https://github.com/HemantKArya/audioread.git to /tmp/pip-install-32e1pp1s/audioread_aa01ed2dbb1c4a3b9885be3df2131cd4\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/HemantKArya/audioread.git /tmp/pip-install-32e1pp1s/audioread_aa01ed2dbb1c4a3b9885be3df2131cd4\n",
            "  Resolved https://github.com/HemantKArya/audioread.git to commit 8ead66d8156a18ca1a2e39752c4c4165162124fd\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting librosa==0.9.2 (from -r requirements.txt (line 2))\n",
            "  Downloading librosa-0.9.2-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting mido==1.3.2 (from -r requirements.txt (line 3))\n",
            "  Downloading mido-1.3.2-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting numpy==1.24.3 (from -r requirements.txt (line 4))\n",
            "  Downloading numpy-1.24.3.tar.gz (10.9 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m>\u001b[0m No available output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Failed to build 'numpy' when getting requirements to build wheel\u001b[0m\u001b[31m\n",
            "\u001b[0mProcessing /content/Melodfy\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m>\u001b[0m No available output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Failed to build 'file:///content/Melodfy' when getting requirements to build wheel\u001b[0m\u001b[31m\n",
            "\u001b[0mffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "libavutil      56. 70.100 / 56. 70.100\n",
            "libavcodec     58.134.100 / 58.134.100\n",
            "libavformat    58. 76.100 / 58. 76.100\n",
            "libavdevice    58. 13.100 / 58. 13.100\n",
            "libavfilter     7.110.100 /  7.110.100\n",
            "libswscale      5.  9.100 /  5.  9.100\n",
            "libswresample   3.  9.100 /  3.  9.100\n",
            "libpostproc    55.  9.100 / 55.  9.100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'melodfy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4247054577.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ffmpeg -version'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmelodfy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maudio_to_midi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0maudio_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"my_piano.wav\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'melodfy'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "def euclidean_distance(x1, x2):\n",
        "    distance = np.sqrt(np.sum((x1-x2)**2))\n",
        "    return distance\n",
        "\n",
        "class KNN:\n",
        "    def __init__(self, k=3):\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = [self._predict(x) for x in X]\n",
        "        return predictions\n",
        "\n",
        "    def _predict(self, x):\n",
        "        distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n",
        "\n",
        "        k_indices = np.argsort(distances)[:self.k]\n",
        "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
        "\n",
        "        most_common = Counter(k_nearest_labels).most_common()\n",
        "        return most_common[0][0]"
      ],
      "metadata": {
        "id": "f3jGWDzFvRBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pretty_midi\n",
        "from music21 import converter, stream, midi\n",
        "import os\n",
        "\n",
        "# ------------------------\n",
        "# Step 1: Convert piano roll  MIDI\n",
        "# ------------------------\n",
        "def pianoroll_to_midi_pm(roll, output_file, fs=16):\n",
        "    midi_data = pretty_midi.PrettyMIDI()\n",
        "    piano = pretty_midi.Instrument(program=0)\n",
        "    n_steps, n_notes = roll.shape\n",
        "\n",
        "    for pitch_idx in range(n_notes):\n",
        "        note_active = False\n",
        "        for t in range(n_steps):\n",
        "            vel = int(roll[t, pitch_idx] * 127)\n",
        "            if vel > 0 and not note_active:\n",
        "                note_active, start = True, t/fs\n",
        "            elif (vel == 0 or t==n_steps-1) and note_active:\n",
        "                note_active = False\n",
        "                end = t/fs\n",
        "                piano.notes.append(pretty_midi.Note(velocity=max(vel,60),\n",
        "                                                    pitch=pitch_idx+21,\n",
        "                                                    start=start,\n",
        "                                                    end=end))\n",
        "    midi_data.instruments.append(piano)\n",
        "    midi_data.write(output_file)\n",
        "    print(\"Saved MIDI:\", output_file)\n",
        "\n",
        "# ------------------------\n",
        "# Step 2: Convert MIDI  MusicXML\n",
        "# ------------------------\n",
        "def midi_to_musicxml(midi_file, xml_file):\n",
        "    score = converter.parse(midi_file)\n",
        "    score.write('musicxml', fp=xml_file)\n",
        "    print(\"Saved MusicXML:\", xml_file)\n",
        "\n",
        "# ------------------------\n",
        "# Step 3: Test with model output\n",
        "# ------------------------\n",
        "os.makedirs(\"test_output\", exist_ok=True)\n",
        "\n",
        "midi_file = \"test_output/test_bar.mid\"\n",
        "xml_file  = \"test_output/test_bar.xml\"\n",
        "\n",
        "# Assume 'output' is your model piano roll (0/1)\n",
        "pianoroll_to_midi_pm(output, midi_file)\n",
        "midi_to_musicxml(midi_file, xml_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBBk9FPyZ8AX",
        "outputId": "fd42d8f8-2023-453c-cc11-29c0ac1e50c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved MIDI: test_output/test_bar.mid\n",
            "Saved MusicXML: test_output/test_bar.xml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    output = model(roll_tensor).squeeze(0).numpy()\n",
        "\n",
        "print(\"Output shape:\", output.shape)\n",
        "print(\"Non-zero notes:\", np.sum(output > 0))\n",
        "print(\"Max value in output:\", np.max(output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix5qwSuoaqNe",
        "outputId": "946c87bb-04d5-4204-ff54-f8d74ea44aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: (16, 88)\n",
            "Non-zero notes: 1408\n",
            "Max value in output: 0.51992184\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1-hPgfRZ_d-Df1gdj4dNp9CHrmAoGM-Ix",
      "authorship_tag": "ABX9TyNy3yrS2rWqL5FDDLuuTEdJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}